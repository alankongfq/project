{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Salaries & Web Scraping\n",
    "## Scraping Indeed.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 1,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683255529,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pk\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 2,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683256156,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "from wordcloud import (WordCloud, get_single_color_func)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Class to output a nice graphic with words, where size of words = occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 3,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683256724,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "class SimpleGroupedColorFunc(object):\n",
    "    \"\"\"Create a color function object which assigns EXACT colors\n",
    "       to certain words based on the color to words mapping\n",
    "\n",
    "       Parameters\n",
    "       ----------\n",
    "       color_to_words : dict(str -> list(str))\n",
    "         A dictionary that maps a color to the list of words.\n",
    "\n",
    "       default_color : str\n",
    "         Color that will be assigned to a word that's not a member\n",
    "         of any value from color_to_words.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, color_to_words, default_color):\n",
    "        self.word_to_color = {word: color\n",
    "                              for (color, words) in color_to_words.items()\n",
    "                              for word in words}\n",
    "\n",
    "        self.default_color = default_color\n",
    "\n",
    "    def __call__(self, word, **kwargs):\n",
    "        return self.word_to_color.get(word, self.default_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 6,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683264591,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "def pltbarangcantik(df):\n",
    "    text = ''\n",
    "    for kerja in df['jobs'].unique():\n",
    "        text += (str(kerja) + ' ') * int(df.importance[kerja] * 10000)\n",
    "\n",
    "    positives = [str(index) for index in df.head(20).index if df.impact_coef[index]>0]\n",
    "    negatives = [str(index) for index in df.head(20).index if df.impact_coef[index]<0]\n",
    "\n",
    "    # Since the text is small collocations are turned off and text is lower-cased\n",
    "    wc = WordCloud(background_color=\"white\", collocations=False).generate(text.lower())\n",
    "\n",
    "    color_to_words = {'blue': positives, 'brown': negatives}\n",
    "\n",
    "    default_color = 'black'\n",
    "\n",
    "    # Create a color function with single tone\n",
    "    grouped_color_func = SimpleGroupedColorFunc(color_to_words, default_color)\n",
    "\n",
    "    # Apply our color function\n",
    "    wc.recolor(color_func=grouped_color_func)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(12,10))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps a better scraper than Irvin's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Countries = {\"SG\":\"Singapore\",\"US\":\"United States\",\"MY\":\"Malaysia\",\"HK\":\"Hong Kong\",\"UK\":'United Kingdom'}\n",
    "\n",
    "Target_cities= {'US':['New York', 'San Francisco', 'Austin', 'Seattle', 'San Jose', 'Boston'\n",
    "                  'Los Angeles', 'Philadelphia', 'Atlanta', 'Dallas', 'Chicago',\n",
    "                  'Pittsburgh', 'Portland', 'Phoenix', 'Denver', 'Houston','Miami', 'Washington DC',\"Baltimore, MD\"],\n",
    "                'SG':[\"Singapore\"]\n",
    "                'UK':[\"\"]\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 8,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683264635,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "URL = {\"SG\":\"https://www.indeed.com.sg/jobs\",\n",
    "       \"US\":\"https://www.indeed.com/jobs\",\n",
    "       \"MY\":\"https://www.indeed.com.my/jobs\",\n",
    "       \"HK\":\"https://www.indeed.hk/jobs\",\n",
    "       \"IR\":\"https://ie.indeed.com\"\n",
    "       \"ES\":\" \"\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 9,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683264647,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "max_results_per_city = 20000\n",
    "#put data scientist as a placeholder, will be filled with the list of jobs later\n",
    "parameters = {'q': 'data scientist', 'radius': '100', 'start':1}\n",
    "#list of jobs\n",
    "jobs = ['data scientist','data analyst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.indeed.com.sg/jobs\"\n",
    "html = requests.get(url, params=url_params)\n",
    "soup = BeautifulSoup(html.text, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 10,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683264685,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "def scrape_page_to_df(url, url_params, country):\n",
    "    \"\"\"\n",
    "    extract information from a results page and save to an existing csv\n",
    "    :param url: url template\n",
    "    :param url_params: a dictionary to feed to params argument in requests.get (based on the parameters I defined above, and I'll make a wrapper to do this below)\n",
    "    :return: a pandas dataframe containing the extracted information\n",
    "    \"\"\"\n",
    "    # create a empty dictionary to store extracted information\n",
    "    scraped_data = {'location': [],\n",
    "                  'company': [],\n",
    "                  'title': [],\n",
    "                  'salary': [],\n",
    "                  'description': [],\n",
    "                  'review': [],\n",
    "                  'star': [],\n",
    "                  'country':[]\n",
    "                  }\n",
    "\n",
    "    html = requests.get(url, params=url_params)\n",
    "\n",
    "    # make sure the response status is ok\n",
    "    assert html.status_code == requests.codes.ok\n",
    "\n",
    "    soup = BeautifulSoup(html.text, 'lxml')\n",
    "\n",
    "    #helper function to extract results\n",
    "    ## input soup object into function\n",
    "\n",
    "    def extract_results(soup):\n",
    "        return soup.find_all('div', class_='result')\n",
    "\n",
    "    results = extract_results(soup)\n",
    "\n",
    "  #helper functions to extract information\n",
    "    def extract_location(result):\n",
    "        \"\"\"extract job location\"\"\"\n",
    "        try:\n",
    "            location = result.find('span', class_='location').get_text().strip()\n",
    "            return location\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_company(result):\n",
    "        \"\"\"extract the name of the company\"\"\"\n",
    "        try:\n",
    "            company = result.find('span', class_='company').get_text().strip()\n",
    "            return company\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    def extract_title(result):\n",
    "        \"\"\"extract the job title\"\"\"\n",
    "        try:\n",
    "            title = result.find('a', attrs={'data-tn-element': \"jobTitle\"}).get('title')\n",
    "            return title\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_salary(result):\n",
    "        \"\"\"extract the salary\"\"\"\n",
    "        try:\n",
    "            salary = result.find('td', class_='snip').\\\n",
    "            find('span', class_='no-wrap').\\\n",
    "            get_text().strip()\n",
    "            return salary\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_description(result):\n",
    "        \"\"\"extract job description snippet\"\"\"\n",
    "        try:\n",
    "            description = result.find('span', class_='summary').get_text().strip()\n",
    "            return description\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    def extract_review(result):\n",
    "        \"\"\"extract the number of reviews for the company\"\"\"\n",
    "        try:\n",
    "            review = result.find('a', attrs={'data-tn-element': \"reviewStars\"})\n",
    "            review = review.find('span', class_=\"slNoUnderline\")\n",
    "            review = review.get_text().strip()\n",
    "            # extract only the number\n",
    "            review = review.replace(',', '').replace(' reviews', '')\n",
    "            return review\n",
    "        except:\n",
    "            return None            \n",
    "\n",
    "    \n",
    "    def extract_star(result):\n",
    "        \"\"\"extract a number (width) that is proportional to the number of stars\n",
    "        shown for the company\"\"\"\n",
    "        try:\n",
    "            # the 'style' attribute dictates how many stars are filled with color\n",
    "            star = result.find('span', class_='rating').get('style')\n",
    "            # extract only the number\n",
    "            star = star.replace('width:', '').replace('px', '')\n",
    "            return star\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "\n",
    "    # append extracted info to the correspond list\n",
    "    for result in results:\n",
    "        scraped_data['location'].append(extract_location(result))\n",
    "        scraped_data['company'].append(extract_company(result))\n",
    "        scraped_data['title'].append(extract_title(result))\n",
    "        scraped_data['salary'].append(extract_salary(result))\n",
    "        scraped_data['description'].append(extract_description(result))\n",
    "        scraped_data['review'].append(extract_review(result))\n",
    "        scraped_data['star'].append(extract_star(result))\n",
    "        scraped_data['country'].append(country)\n",
    "\n",
    "      # convert the dictionary to a pandas dataframe and returns it\n",
    "    return pd.DataFrame(scraped_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "helper function to remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 11,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683264722,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(df):\n",
    "    \"\"\"remove duplicates and returns a new df\"\"\"\n",
    "    \n",
    "    nrows_before = df.shape[0]\n",
    "    df.drop_duplicates(subset=['company', 'country','description',\n",
    "                               'location', 'salary', 'title'],\n",
    "                       keep='last', inplace=True)\n",
    "    nrows_after = df.shape[0]\n",
    "    \n",
    "    print('{} rows remain after removing duplicates from {} rows.'.format(\n",
    "        nrows_after, nrows_before))\n",
    "    print('{} rows have salary info; {} rows have yearly salary info.'.format(\n",
    "      df.salary.notnull().sum(), df.salary.str.contains('year').sum()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 12,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683264731,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "def scrapper(CountryCode):\n",
    "    print('Current system time: {}'.format(time.ctime()))\n",
    "    \n",
    "   \n",
    "  \n",
    "    # scrape data and save to dataframe\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #Retrieve Parameters to scrape with based on input of Country Code\n",
    "    url = URL[CountryCode]\n",
    "    locations = Target_cities[CountryCode]\n",
    "    country = Countries[CountryCode]\n",
    "    \n",
    "    #Create an empty place holder df, search through every location in that country, but only 1 results, just to get the title and columns\n",
    "    df = scrape_page_to_df(url,parameters,country)\n",
    "    \n",
    "    \n",
    "    for tempat in locations:\n",
    "        for kerja in jobs:\n",
    "            for start in range(0, max_results_per_city, 10):\n",
    "            \n",
    "              \n",
    "                url_params = parameters.copy()\n",
    "                #update the job with the target job that we want, city for target city that we are looking for and start refers to the current page number being scrapped\n",
    "                url_params.update({'l': tempat,'q': kerja, 'start': start})\n",
    "\n",
    "\n",
    "                #insert code to put the scrap stuff into a df here, after each round of loop, concat into a df\n",
    "                df = pd.concat([df,scrape_page_to_df(url, url_params,country)],axis=0)\n",
    "              \n",
    "        print('Finished scraping {}'.format(tempat))\n",
    "    total_time = (time.time() - start_time) / 60\n",
    "    print('Scraping run time: {:.1f} minutes'.format(total_time))\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # remove duplicates\n",
    "    df = remove_duplicates(df)\n",
    "    print('Script finished at {}\\n'.format(time.ctime()))\n",
    "    \n",
    "    #returns the final df\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "execution_count": 13,
      "payload": [],
      "status": "ok",
      "user_expressions": {},
      "user_variables": {}
     },
     "timestamp": 1508683617720,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "SG = scrapper('SG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG.to_pickle('./data/SG.pkl')\n",
    "SG.to_csv('./data/SG.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "status": "aborted"
     },
     "timestamp": 1508683902955,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "ID = scrapper('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID.to_pickle('./data/ID.pkl')\n",
    "ID.to_csv('./data/ID.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "status": "aborted"
     },
     "timestamp": 1508683902976,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "US = scrapper('US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "US.to_pickle('./data/US.pkl')\n",
    "US.to_csv('./data/US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "status": "aborted"
     },
     "timestamp": 1508683902987,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "HK= scrapper('HK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HK.to_pickle('./data/HK.pkl')\n",
    "HK.to_csv('./data/HK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MY=scrapper(\"MY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MY.to_pickle('./data/MY.pkl')\n",
    "MY.to_csv('./data/MY.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": null,
    "executionInfo": {
     "content": {
      "status": "aborted"
     },
     "timestamp": 1508683248977,
     "user": {
      "color": "#1FA15D",
      "displayName": "Nasrudin Salim",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "08405076575781058120",
      "photoUrl": "//lh5.googleusercontent.com/-_losW-TOCfY/AAAAAAAAAAI/AAAAAAAAs2I/-pEq-D9OnXc/s50-c-k-no/photo.jpg",
      "sessionId": "2b925d78e3c2f27b",
      "userId": "108356546527876522753"
     },
     "user_tz": -480
    }
   },
   "outputs": [],
   "source": [
    "alldf =[SG,MY,ID,US,HK]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should pickle these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.load('./data/SG.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "colabVersion": "0.1",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
